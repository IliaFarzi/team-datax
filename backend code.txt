# api/app/agent.py
from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import StructuredTool

import os
from dotenv import load_dotenv

from api.app.google_sheets import list_google_sheets, preview_google_sheet, load_google_sheet_to_dataframe, analyze_google_sheet, list_private_public_sheets, extract_headers_tool
from api.app.models import PreviewGoogleSheetArgs, LoadGoogleSheetArgs, AnalyzeGoogleSheetArgs, ListPrivatePublicSheetArgs, ListGoogleSheetArgs, AnalyzeUploadedFileArgs, ListUploadedFilesArgs
from api.app.upload_router import analyze_uploaded_file, list_uploaded_files

tools = [
    StructuredTool.from_function(
        func=list_google_sheets,
        name="ListGoogleSheets",
        description="List all Google Sheets available to the user. Requires google_id.",
        args_schema=ListGoogleSheetArgs, 
    ),
    StructuredTool.from_function(
        func=preview_google_sheet,
        name="PreviewGoogleSheet",
        description="Preview the first 5 rows of a Google Sheet. Requires sheet_id and google_id.",
        args_schema=PreviewGoogleSheetArgs
    ),
    StructuredTool.from_function(
        func=load_google_sheet_to_dataframe,
        name="LoadGoogleSheet",
        description="Load a complete Google Sheet into a DataFrame for analysis. Requires sheet_id and google_id.",
        args_schema=LoadGoogleSheetArgs
    ),
    StructuredTool.from_function(
        func=analyze_google_sheet,
        name="AnalyzeGoogleSheet",
        description="Analyze a Google Sheet with operations like sum, mean, or filter. Requires sheet_id, google_id, operation, column, and optionally value.",
        args_schema=AnalyzeGoogleSheetArgs
    ),
    StructuredTool.from_function(
        func=list_private_public_sheets,
        name="ListPrivatePublicSheets",
        description="List private and public Google Sheets for a user. Requires google_id.",
        args_schema=ListPrivatePublicSheetArgs 
    ),
    StructuredTool.from_function(
        func=extract_headers_tool,
        name="ExtractSheetHeaders",
        description="Extract headers from a Google Sheet, save to CSV, and upload to MinIO. Requires sheet_id and google_id.",
        args_schema=PreviewGoogleSheetArgs
    ),
    StructuredTool.from_function(
    func=analyze_uploaded_file,
    name="AnalyzeUploadedFile",
    description="Analyze an uploaded CSV or Excel file stored in MinIO. Requires filename.",
    args_schema=AnalyzeUploadedFileArgs
    ),
    StructuredTool.from_function(
    func=list_uploaded_files,
    name="ListUploadedFiles",
    description="List all files uploaded by a specific user (google_id) with metadata.",
    args_schema=ListUploadedFilesArgs
)
    ]

# Load environment variables
load_dotenv(".env")

# Access API keys
openrouter_api_key = os.getenv("OPENROUTER_API_KEY")
openrouter_base_url = os.getenv("OPENROUTER_API_BASE")

def get_agent(model_name: str):
    llm = ChatOpenAI(
        model_name=model_name,
        openai_api_key=openrouter_api_key,
        openai_api_base=openrouter_base_url,
        temperature=0.7,
        max_tokens=4096,
        top_p=0.9,
        frequency_penalty=0.1,
        presence_penalty=0.1
    )
    system_message = """
    You are a data analysis assistant that helps users interact with their Google Sheets. Use the provided tools to:
    - List available Google Sheets (ListGoogleSheets).
    - Preview the first 5 rows of a specific sheet (PreviewGoogleSheet).
    - Load a sheet into a DataFrame for analysis (LoadGoogleSheet).
    - Perform analysis like sum, mean, or filtering on a sheet (AnalyzeGoogleSheet).
    - List private and public Google Sheets for a user. Requires google_id(ListPrivatePublicSheets).
    - List all files uploaded by a specific user (google_id) with metadata.(ListUploadedFiles)
    - Analyze an uploaded CSV or Excel file stored in MinIO. Requires filename.(AnalyzeUploadedFile)
    Provide clear and concise responses. If a user request requires a specific sheet, ask for the sheet_id if not provided.
    """
    llm = llm.with_config(system_message=system_message)
    return create_react_agent(llm, tools=tools)

#api/app/auth_reouter.py
from fastapi import APIRouter, HTTPException, Request, Depends
from fastapi.responses import RedirectResponse
from fastapi.security import OAuth2PasswordBearer

from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build

from jose import JWTError, jwt
import uuid
import os
from datetime import datetime, timezone, timedelta
from dotenv import load_dotenv
import bcrypt
bcrypt.__about__ = bcrypt
from passlib.context import CryptContext

from api.app.agent import get_agent
from api.app.chat_router import sessions, DEFAULT_MODEL, WELCOME_MESSAGE
from api.app.database import db, save_message
from api.app.google_sheets import credentials_to_dict, CLIENT_SECRETS_FILE, SCOPES, REDIRECT_URI


# Load environment variables
load_dotenv(".env")

SECRET_KEY = os.getenv("JWT_SECRET")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 60

auth_router = APIRouter(prefix="/auth", tags=["Authentication"])
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/login")

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.now(timezone.utc) + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def decode_token(token: str):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload.get("sub")
    except JWTError:
        return None

@auth_router.get("/signup")
async def google_signup():
    """Start Google OAuth flow for signup"""
    flow = Flow.from_client_secrets_file(
        str(CLIENT_SECRETS_FILE),
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )
    auth_url, state = flow.authorization_url(prompt='consent')
    return RedirectResponse(auth_url)

@auth_router.get("/login")
async def google_login():
    """Start Google OAuth flow for login"""
    flow = Flow.from_client_secrets_file(
        str(CLIENT_SECRETS_FILE),
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )
    auth_url, state = flow.authorization_url(prompt='consent')
    return RedirectResponse(auth_url)

@auth_router.get("/google/callback")
async def google_auth_callback(request: Request):
    state = request.query_params.get('state')
    code = request.query_params.get('code')
    
    if not code:
        raise HTTPException(status_code=400, detail="No code provided")

    flow = Flow.from_client_secrets_file(
        CLIENT_SECRETS_FILE,
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )
    flow.fetch_token(code=code)
    credentials = flow.credentials

    user_info_service = build("oauth2", "v2", credentials=credentials)
    user_info = user_info_service.userinfo().get().execute()
    google_id = user_info.get("id")
    name = user_info.get("name")
    email = user_info.get("email")

    if not google_id or not email:
        raise HTTPException(status_code=400, detail="Failed to retrieve user info")

    drive_service = build("drive", "v3", credentials=credentials)
    files = drive_service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        fields="files(id, name, sharedWithMeTime, owners)"
    ).execute().get("files", [])
    private_sheets = [{"id": f["id"], "name": f["name"]} for f in files if f.get("owners", [{}])[0].get("me", True)]
    public_sheets = [{"id": f["id"], "name": f["name"]} for f in files if f.get("sharedWithMeTime")]

    users_col = db["users"]
    users_col.update_one(
        {"google_id": google_id},
        {"$set": {
            "name": name,
            "email": email,
            "google_id": google_id,
            "private_spreadsheets": private_sheets,
            "public_spreadsheets": public_sheets,
            "google_credentials": credentials_to_dict(credentials),
            "last_login": datetime.now(timezone.utc)
        }},
        upsert=True
    )

    token = create_access_token({"sub": google_id})
    session_id = str(uuid.uuid4())
    sessions[session_id] = {"agent": get_agent(DEFAULT_MODEL)}
    save_message(session_id, "assistant", WELCOME_MESSAGE)

    # Save google_id and credentials in session
    request.session['google_id'] = google_id
    request.session['google_credentials'] = credentials_to_dict(credentials)

    return {
        "access_token": token,
        "token_type": "bearer",
        "session_id": session_id,
        "welcome": f"Welcome {name}! You have successfully signed up/logged in.",
        "user": {
            "google_id": google_id,
            "name": name,
            "email": email
        },
        "private_spreadsheets": private_sheets,
        "public_spreadsheets": public_sheets
    }

def get_current_user(token: str = Depends(oauth2_scheme)):
    user = decode_token(token)
    if not user:
        raise HTTPException(status_code=401, detail="Invalid token")
    
    # Verify user exists in MongoDB
    users_col = db["users"]
    user_doc = users_col.find_one({"google_id": user})
    if not user_doc:
        raise HTTPException(status_code=401, detail="User not found")
    return user_doc

#api/app/chat_router.py
from fastapi import APIRouter, HTTPException, Request
import traceback

from api.app.models import UserMessage
from api.app.database import save_message, get_history
from api.app.agent import get_agent

chat_router = APIRouter(prefix="/Chat", tags=['Chat with LLM'])
sessions = {}

#DEFAULT_MODEL = "mistralai/mistral-7b-instruct"
#DEFAULT_MODEL = "qwen/qwen2.5-72b-instruct"
#DEFAULT_MODEL = "mistralai/mistral-nemo"
DEFAULT_MODEL = "mistralai/mistral-small-3.2-24b-instruct"


WELCOME_MESSAGE = "hi, how can i help you?üòä"

@chat_router.post("/send_message")
def send_message(message: UserMessage, request:Request):
    session_id = message.session_id
    content = message.content

    
    # If the session does not exist, create it
    if session_id not in sessions:
        sessions[session_id] = {"agent": get_agent(DEFAULT_MODEL)}

    session = sessions.get(session_id)
    if not session:
        raise HTTPException(status_code=403, detail="Invalid or expired session_id.")

    # Save the user's message first
    save_message(session_id, "user", content) # We moved this line here because the model must first have a message from the user in addition to its own message for the history to work properly.

    
    # Get the history AFTER saving the user message
    history = get_history(session_id)

    # Check message count (now including the new user message)
    user_message_count = sum(1 for msg in history if msg["role"] == "user")
    if user_message_count > 20: 
        return {
            "response": "‚ö†Ô∏è You can only send 20 messages in this session. Please start a new session."}

    # Continue the usual process
    agent = session["agent"]
    
    
    try:
        response = agent.invoke({
            "messages": history,
            "session": request.session  # Transfer session to agent
        })
        ai_message = response["messages"][-1]
        output = ai_message.content
        # Save the AI's response
        save_message(session_id, "assistant", output)
    except Exception as e:
        traceback.print_exc()
        output = f"‚ùó Error processing response: {str(e)}"
        # Even if processing fails, the user message is already saved.
    return {"response": output}

@chat_router.get("/get_history/{session_id}")
def get_chat_history(session_id: str):
    session = sessions.get(session_id)
    if not session:
        raise HTTPException(status_code=404, detail="Session not found")

    return get_history(session_id)

#api/app/database.py
from pymongo.mongo_client import MongoClient
from pymongo.server_api import ServerApi
import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv(".env")

# Get MongoDB configuration
MONGO_URI = os.getenv("MONGO_URI")
MONGO_DB_NAME = os.getenv("MONGO_DB_NAME")
MONGO_COLLECTION_NAME = os.getenv("MONGO_COLLECTION_NAME")

# Initialize MongoDB client and database
try:
    client = MongoClient(MONGO_URI, server_api=ServerApi('1'))
    client.admin.command('ping')
    print("‚úÖ Pinged your deployment. Connected to MongoDB successfully!")
    
    db = client[MONGO_DB_NAME]
    chat_sessions_collection = db[MONGO_COLLECTION_NAME]
    users_col = db["users"]  # New collection for users
    
    db_list = client.list_database_names()
    if MONGO_DB_NAME in db_list:
        print(f"‚úÖ Database '{MONGO_DB_NAME}' exists.")
    else:
        print(f"‚ÑπÔ∏è  Database '{MONGO_DB_NAME}' will be created on first use.")

    col_list = db.list_collection_names()
    if MONGO_COLLECTION_NAME in col_list:
        print(f"‚úÖ Collection '{MONGO_COLLECTION_NAME}' exists.")
    else:
        print(f"‚ÑπÔ∏è  Collection '{MONGO_COLLECTION_NAME}' will be created on first use.")
    
    if "users" in col_list:
        print(f"‚úÖ Collection 'users' exists.")
    else:
        print(f"‚ÑπÔ∏è  Collection 'users' will be created on first use.")

except Exception as e:
    print(f"‚ùå Error connecting to MongoDB: {e}")
    raise e

def save_message(session_id: str, role: str, content: str):
    try:
        result = chat_sessions_collection.update_one(
            {"session_id": session_id},
            {
                "$push": {"messages": {"role": role, "content": content}},
                "$setOnInsert": {"session_id": session_id}
            },
            upsert=True
        )
    except Exception as e:
        print(f"‚ùó Error saving message to MongoDB for session {session_id}: {e}")

def get_history(session_id: str) -> list:
    try:
        document = chat_sessions_collection.find_one({"session_id": session_id})
        if document and "messages" in document:
            return document["messages"]
        return []
    except Exception as e:
        print(f"‚ùó Error retrieving history from MongoDB for session {session_id}: {e}")
        return []

# api/app/google_sheets.py
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import Flow
from googleapiclient.discovery import build
from google.auth.transport.requests import Request

from api.app.database import db

import os
from datetime import datetime, timezone
from typing import Dict, List, Any
import pandas as pd

from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import RedirectResponse
from fastapi import BackgroundTasks


from minio import Minio
from minio.error import S3Error

def upload_to_minio(csv_filepath: str, sheet_id: str, google_id: str, sheet_name: str):
    """Upload CSV file to MinIO and save metadata to MongoDB"""
    # Initialize MinIO client
    minio_client = Minio(
        endpoint=os.getenv("MINIO_ENDPOINT"),
        access_key=os.getenv("MINIO_ACCESS_KEY"),
        secret_key=os.getenv("MINIO_SECRET_KEY"),
        secure=False  # ÿ®ÿ±ÿß€å ÿ™Ÿàÿ≥ÿπŸá ŸÖÿ≠ŸÑ€å
    )

    bucket_name = "spreadsheet-headers"
    object_name = f"{google_id}/{sheet_id}.csv"

    try:
        # Create bucket if it doesn't exist
        if not minio_client.bucket_exists(bucket_name):
            minio_client.make_bucket(bucket_name)

        # Upload file
        minio_client.fput_object(bucket_name, object_name, csv_filepath)
        
        # Get file URL
        file_url = f"http://{os.getenv('MINIO_ENDPOINT')}/{bucket_name}/{object_name}"

        # Save metadata to MongoDB
        metadata_col = db["spreadsheet_metadata"]
        metadata_col.update_one(
            {"sheet_id": sheet_id, "google_id": google_id},
            {"$set": {
                "sheet_name": sheet_name,
                "type": "private" if sheet_name in list_private_sheets(google_id) else "public",
                "google_id": google_id,
                "file_path": file_url,
                "uploaded_at": datetime.now(timezone.utc)
            }},
            upsert=True
        )

        # Clean up local file
        os.remove(csv_filepath)
        
        print(f"File {csv_filepath} uploaded to MinIO at {file_url}")
        return file_url
        
    except S3Error as e:
        print(f"Error uploading to MinIO: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to upload to MinIO: {str(e)}")

google_sheets_auth_router = APIRouter(prefix="/auth", tags=["Google Sheets Auth"])
google_sheets_preview_router = APIRouter(prefix="/sheets", tags=["Google Sheets for tools"])

# Google OAuth Setup
os.environ["OAUTHLIB_INSECURE_TRANSPORT"] = "1"  # for development only

# Path to OAuth client secrets file
CLIENT_SECRETS_FILE = os.path.join(os.path.dirname(__file__), "client_secret.json") 
SCOPES = [
    "https://www.googleapis.com/auth/userinfo.email",
    "https://www.googleapis.com/auth/userinfo.profile",
    "https://www.googleapis.com/auth/spreadsheets.readonly",
    "https://www.googleapis.com/auth/drive.metadata.readonly",
    "openid"
]
REDIRECT_URI = "http://localhost:8000/auth/google/callback"

@google_sheets_auth_router.get("/google")
async def google_auth(request: Request):
    """Start OAuth flow for Google Sheets access"""
    flow = Flow.from_client_secrets_file(
        str(CLIENT_SECRETS_FILE),
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )
    
    auth_url, _ = flow.authorization_url(prompt='consent')
    return RedirectResponse(auth_url)

@google_sheets_auth_router.get("/google/callback")
async def google_auth_callback(request: Request):
    state = request.query_params.get('state')
    code = request.query_params.get('code')
    
    flow = Flow.from_client_secrets_file(
        CLIENT_SECRETS_FILE,
        scopes=SCOPES,
        redirect_uri=REDIRECT_URI
    )

    flow.fetch_token(code=code)
    credentials = flow.credentials

    # Get user info
    user_info_service = build("oauth2", "v2", credentials=credentials)
    user_info = user_info_service.userinfo().get().execute()
    google_id = user_info.get("id")
    name = user_info.get("name")
    email = user_info.get("email")

    # Get spreadsheet list
    drive_service = build("drive", "v3", credentials=credentials)
    files = drive_service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        fields="files(id, name, sharedWithMeTime, owners)"
    ).execute().get("files", [])
    private_sheets = [{"id": f["id"], "name": f["name"]} for f in files if f.get("owners", [{}])[0].get("me", True)]
    public_sheets = [{"id": f["id"], "name": f["name"]} for f in files if f.get("sharedWithMeTime")]
    
    # Save user info and credentials to MongoDB
    users_col = db["users"]
    users_col.update_one(
        {"google_id": google_id},
        {"$set": {
            "name": name,
            "email": email,
            "google_id": google_id,
            "private_spreadsheets": private_sheets,
            "public_spreadsheets": public_sheets,
            "google_credentials": credentials_to_dict(credentials),
            "last_login": datetime.now(timezone.utc)
        }},
        upsert=True
    )

    return {
        'status': 'success',
        'message': f'Successfully connected to Google Sheets. Welcome {name}!',
        'user': {
            'google_id': google_id,
            'name': name,
            'email': email
        },
        'private_spreadsheets': private_sheets,
        'public_spreadsheets': public_sheets
    }
def credentials_to_dict(credentials):
    """Convert credentials object to dictionary for session storage"""
    return {
        'token': credentials.token,
        'refresh_token': credentials.refresh_token,
        'token_uri': credentials.token_uri,
        'client_id': credentials.client_id,
        'client_secret': credentials.client_secret,
        'scopes': credentials.scopes
    }

def get_credentials(google_id: str):
    """Get credentials from MongoDB"""
    users_col = db["users"]
    user = users_col.find_one({"google_id": google_id})
    if not user or "google_credentials" not in user:
        return None

    credentials = Credentials(**user["google_credentials"])
    if credentials.expired and credentials.refresh_token:
        credentials.refresh(Request())
        users_col.update_one(
            {"google_id": google_id},
            {"$set": {"google_credentials": credentials_to_dict(credentials)}}
        )
    return credentials

def list_private_sheets(google_id: str) -> List[str]:
    """Return list of private sheet names"""
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")
    service = build('drive', 'v3', credentials=credentials)
    results = service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        fields="files(id, name, sharedWithMeTime, owners)"
    ).execute().get("files", [])
    return [f["name"] for f in results if f.get("owners", [{}])[0].get("me", True)]

@google_sheets_preview_router.get("/")
async def list_sheets(request: Request):
    """List user's Google Sheets files"""
    credentials = get_credentials(request.session)
    if not credentials:
        raise HTTPException(status_code=401, detail="Not connected to Google Sheets")

    service = build('drive', 'v3', credentials=credentials)

    results = service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        pageSize=10,
        fields="nextPageToken, files(id, name)"
    ).execute()

    items = results.get('files', [])
    return {"sheets": [{"id": item["id"], "name": item["name"]} for item in items]}

@google_sheets_preview_router.get("/{sheet_id}/preview")
async def preview_sheet(sheet_id: str, request: Request):
    """Get the first 5 rows from a Google Sheet"""
    credentials = get_credentials(request.session)
    if not credentials:
        raise HTTPException(status_code=401, detail="Not connected to Google Sheets")

    service = build('sheets', 'v4', credentials=credentials)

    result = service.spreadsheets().values().get(
        spreadsheetId=sheet_id,
        range='A1:Z5'
    ).execute()

    values = result.get('values', [])

    headers = values[0] if values else []
    rows = values[1:5] if len(values) > 1 else []

    return {
        "headers": headers,
        "rows": rows,
        "sheet_id": sheet_id
    }

@google_sheets_preview_router.get("/{sheet_id}/extract_headers")
async def extract_sheet_headers(sheet_id: str, request: Request, background_tasks: BackgroundTasks):
    """Extract headers from a Google Sheet and save to CSV, then upload to MinIO"""
    google_id = request.session.get('google_id')
    if not google_id:
        raise HTTPException(status_code=401, detail="User not authenticated")
    
    # Get sheet name from list_google_sheets
    sheets = list_google_sheets(google_id)
    sheet_name = next((sheet['name'] for sheet in sheets if sheet['id'] == sheet_id), None)
    if not sheet_name:
        raise HTTPException(status_code=404, detail="Sheet not found")

    # Extract headers and save to CSV
    csv_filepath = extract_headers_to_csv(sheet_id, google_id, sheet_name)
    
    # Upload to MinIO and get file URL
    file_url = upload_to_minio(csv_filepath, sheet_id, google_id, sheet_name)
    
    return {"message": f"Headers extracted and uploaded to MinIO", "file_url": file_url}

# Tools for internal use or reuse

def list_google_sheets(google_id: str) -> List[Dict[str, str]]:
    """Return list of user's Google Sheets"""
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")
    service = build('drive', 'v3', credentials=credentials)
    results = service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        pageSize=20,
        fields="files(id, name)"
    ).execute()
    items = results.get('files', [])
    return [{"id": item["id"], "name": item["name"]} for item in items]

def preview_google_sheet(sheet_id: str, google_id: str) -> Dict[str, Any]:
    """Preview the first 5 rows of a Google Sheet"""
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")
    service = build('sheets', 'v4', credentials=credentials)
    result = service.spreadsheets().values().get(
        spreadsheetId=sheet_id,
        range='A1:Z5'
    ).execute()
    values = result.get('values', [])
    if not values:
        return {"headers": [], "rows": [], "sheet_id": sheet_id}
    headers = values[0]
    rows = values[1:5]
    return {"headers": headers, "rows": rows, "sheet_id": sheet_id}

def load_google_sheet_to_dataframe(sheet_id: str, google_id: str) -> pd.DataFrame:
    """Load entire Google Sheet into a pandas DataFrame"""
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")
    service = build('sheets', 'v4', credentials=credentials)
    result = service.spreadsheets().values().get(
        spreadsheetId=sheet_id,
        range='A1:Z1000'
    ).execute()
    values = result.get('values', [])
    if not values:
        raise ValueError("No data found in the spreadsheet.")
    df = pd.DataFrame(values[1:], columns=values[0])
    return df

def analyze_google_sheet(sheet_id: str, session, operation: str, column: str, value: str = None) -> Dict[str, Any]:
    """Analyze data in a Google Sheet"""
    df = load_google_sheet_to_dataframe(sheet_id, session)
    
    if operation == "sum":
        result = df[column].astype(float).sum()
        return {"result": result, "operation": "sum", "column": column}
    elif operation == "mean":
        result = df[column].astype(float).mean()
        return {"result": result, "operation": "mean", "column": column}
    elif operation == "filter":
        if value:
            result = df[df[column].astype(str) == value]
            return {"result": result.to_dict(), "operation": "filter", "column": column, "value": value}
        else:
            raise ValueError("Filter operation requires a value")
    else:
        raise ValueError(f"Unsupported operation: {operation}")

def list_private_public_sheets(google_id: str) -> Dict[str, List[str]]:
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")
    service = build('drive', 'v3', credentials=credentials)
    results = service.files().list(
        q="mimeType='application/vnd.google-apps.spreadsheet'",
        fields="files(id, name, sharedWithMeTime, owners)"
    ).execute().get("files", [])
    private_sheets = [{"id": f["id"], "name": f["name"]} for f in results if f.get("owners", [{}])[0].get("me", True)]
    public_sheets = [{"id": f["id"], "name": f["name"]} for f in results if f.get("sharedWithMeTime")]
    return {"private_sheets": private_sheets, "public_sheets": public_sheets}


def extract_headers_to_csv(sheet_id: str, google_id: str, sheet_name: str) -> str:
    """Extract headers from a Google Sheet and save them to a CSV file"""
    credentials = get_credentials(google_id)
    if not credentials:
        raise ValueError("Not connected to Google Sheets. Please connect first.")

    service = build('sheets', 'v4', credentials=credentials)
    result = service.spreadsheets().values().get(
        spreadsheetId=sheet_id,
        range='A1:Z1'  # ŸÅŸÇÿ∑ ÿ±ÿØ€åŸÅ ÿßŸàŸÑ (ŸáÿØÿ±Ÿáÿß)
    ).execute()

    headers = result.get('values', [[]])[0]
    if not headers:
        raise ValueError("No headers found in the spreadsheet.")

    # Create a DataFrame with headers
    df = pd.DataFrame([headers], columns=[f"column_{i+1}" for i in range(len(headers))])
    
    # Generate a unique filename
    csv_filename = f"headers_{sheet_id}_{google_id}.csv"
    csv_filepath = os.path.join("temp", csv_filename)  # ÿ∞ÿÆ€åÿ±Ÿá ŸÖŸàŸÇÿ™ ÿØÿ± ŸæŸàÿ¥Ÿá temp
    
    # Create temp directory if it doesn't exist
    os.makedirs("temp", exist_ok=True)
    
    # Save to CSV
    df.to_csv(csv_filepath, index=False)
    
    return csv_filepath

def extract_headers_tool(sheet_id: str, google_id: str) -> Dict[str, str]:
    """Extract headers from a Google Sheet, save to CSV, and upload to MinIO"""
    sheet_name = next((sheet['name'] for sheet in list_google_sheets(google_id) if sheet['id'] == sheet_id), None)
    if not sheet_name:
        raise ValueError("Sheet not found")
    csv_filepath = extract_headers_to_csv(sheet_id, google_id, sheet_name)
    file_url = upload_to_minio(csv_filepath, sheet_id, google_id, sheet_name)
    return {"file_url": file_url, "sheet_name": sheet_name}


# api/app/main.py
from fastapi import FastAPI
from fastapi.responses import RedirectResponse
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.sessions import SessionMiddleware

from dotenv import load_dotenv
import os

from api.app.chat_router import chat_router
from api.app.auth_router import auth_router
from api.app.upload_router import upload_router

from api.app.google_sheets import google_sheets_auth_router , google_sheets_preview_router

load_dotenv(".env")

SECRET_KEY = os.getenv("SESSION_SECRET_KEY")
FRONTEND_ORIGIN = os.getenv("FRONTEND_URL")  

app = FastAPI(title="Smart Support Chatbot", description="API for chat, file upload, Google Sheets integration, and data analysis")


# ‚úÖ Session middleware 
app.add_middleware(
    SessionMiddleware,
    secret_key=SECRET_KEY,
    same_site="none",  
    https_only=False,
    domain="localhost"
)

# ‚úÖ CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[FRONTEND_ORIGIN],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ‚úÖ Register routers
app.include_router(auth_router)
app.include_router(google_sheets_auth_router)
app.include_router(google_sheets_preview_router)
app.include_router(upload_router)
app.include_router(chat_router)

@app.get("/")
def root():
    return RedirectResponse("/docs")

@app.get("/favicon.ico")
def favicon():
    return {}


#api/app/models.py
from pydantic import BaseModel, EmailStr, field_validator, Field
from typing import List, Optional

class Message(BaseModel):
    role: str  # 'user', 'assistant', 'system', etc.
    content: str

class ChatSession(BaseModel):
    session_id: str
    model_name: Optional[str]
    history: List[Message] = []

class UserMessage(BaseModel):
    session_id: str
    content: str

class ModelAction(BaseModel):
    action: str 
    model_name: str | None = None

# Define a request class for registration
class SignUpRequest(BaseModel):
    email: EmailStr
    password: str
   
    @field_validator('email') 
    @classmethod 
    def validate_email_domain(cls, v): 
        """
        Validates that the email domain is example.com.
        Modify the domain list as needed.
        """
        allowed_domains = ["gmail.com", "email.com"]
        # Change: Error checking if email is empty
        if not v: 
            raise ValueError('Email is required')
        domain = v.split('@')[-1].lower()
        if domain not in allowed_domains:
            raise ValueError(f'ŸÅŸÇÿ∑ ÿß€åŸÖ€åŸÑ‚ÄåŸáÿß€å ÿ®ÿß ÿØÿßŸÖŸÜŸá‚ÄåŸáÿß€å {", ".join(allowed_domains)} ŸÖÿ¨ÿßÿ≤ Ÿáÿ≥ÿ™ŸÜÿØ.')
        return v

class LoginRequest(BaseModel):
    email: EmailStr
    password: str
    
    @field_validator('email')
    @classmethod 
    def validate_email_domain(cls, v):
         if not v:
             raise ValueError('Email is required')
         allowed_domains = ["gmail.com", "email.com"]
         domain = v.split('@')[-1].lower()
         if domain not in allowed_domains:
             raise ValueError(f'ŸÅŸÇÿ∑ ÿß€åŸÖ€åŸÑ‚ÄåŸáÿß€å ÿ®ÿß ÿØÿßŸÖŸÜŸá‚ÄåŸáÿß€å {", ".join(allowed_domains)} ŸÖÿ¨ÿßÿ≤ Ÿáÿ≥ÿ™ŸÜÿØ.')
         return v
    
class ListGoogleSheetArgs(BaseModel):
    google_id:str

class ListPrivatePublicSheetArgs(BaseModel):
    google_id:str

class PreviewGoogleSheetArgs(BaseModel):
    """Required arguments for the Google Sheet preview tool"""
    sheet_id: str
    google_id: str

class LoadGoogleSheetArgs(BaseModel):
    """Required arguments for Google Sheet download tool"""
    sheet_id: str
    google_id: str


class AnalyzeGoogleSheetArgs(BaseModel):
    sheet_id: str
    operation: str  # Operation type, such as "sum", "mean", "filter"
    column: str  # Column in question
    value: Optional[str] = None  # To filter
    
class AnalyzeUploadedFileArgs(BaseModel):
    filename: str

class ListUploadedFilesArgs(BaseModel):
    google_id: str

#api/app/upload_router.py
from fastapi import APIRouter, File, UploadFile, HTTPException, Request
from minio import Minio
import pandas as pd
import os
from dotenv import load_dotenv
import tempfile
from datetime import datetime, timezone

from api.app.database import db  # MongoDB client

load_dotenv(".env")

upload_router = APIRouter(prefix="/upload", tags=["File Upload"])

# MinIO Client
minio_client = Minio(
    endpoint=os.getenv("MINIO_ENDPOINT"),
    access_key=os.getenv("MINIO_ACCESS_KEY"),
    secret_key=os.getenv("MINIO_SECRET_KEY"),
    secure=False  # For development only
)

BUCKET_NAME = "user-uploads"

# Create bucket if it doesn't exist
if not minio_client.bucket_exists(BUCKET_NAME):
    minio_client.make_bucket(BUCKET_NAME)

@upload_router.post("/")
async def upload_file(request: Request, file: UploadFile = File(...)):
    """Upload CSV/Excel to MinIO and store metadata in MongoDB."""
    try:
        # Get google_id from session (or other user identifier)
        google_id = request.session.get("google_id", "anonymous")

        # Validate file type
        if not (file.filename.endswith(".csv") or file.filename.endswith(".xlsx")):
            raise HTTPException(status_code=400, detail="Only CSV and Excel files are allowed.")

        # Save temporarily
        with tempfile.NamedTemporaryFile(delete=False) as tmp:
            tmp.write(await file.read())
            tmp_path = tmp.name

        # Upload to MinIO
        object_name = file.filename
        minio_client.fput_object(BUCKET_NAME, object_name, tmp_path)

        # Remove temp file
        os.remove(tmp_path)

        # File URL
        file_url = f"http://{os.getenv('MINIO_ENDPOINT')}/{BUCKET_NAME}/{object_name}"

        # Load file to extract metadata
        if file.filename.endswith(".csv"):
            df = pd.read_csv(file_url)
        else:
            df = pd.read_excel(file_url)

        metadata = {
            "google_id": google_id,
            "filename": object_name,
            "bucket": BUCKET_NAME,
            "url": file_url,
            "rows": len(df),
            "columns": len(df.columns),
            "headers": list(df.columns),
            "uploaded_at": datetime.now(timezone.utc)
        }

        # Store metadata in MongoDB
        metadata_col = db["uploaded_files"]
        metadata_col.insert_one(metadata)

        return {
            "message": "File uploaded and metadata stored successfully",
            "metadata": metadata
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def analyze_uploaded_file(filename: str):
    """Download file from MinIO, load into DataFrame, and analyze basic info."""
    try:
        # Download from MinIO to a temporary file
        tmp_path = tempfile.NamedTemporaryFile(delete=False).name
        minio_client.fget_object(BUCKET_NAME, filename, tmp_path)

        # Load into DataFrame
        if filename.endswith(".csv"):
            df = pd.read_csv(tmp_path)
        elif filename.endswith(".xlsx"):
            df = pd.read_excel(tmp_path)
        else:
            raise HTTPException(status_code=400, detail="Unsupported file format.")

        os.remove(tmp_path)

        # Basic analysis
        analysis = {
            "rows": len(df),
            "columns": len(df.columns),
            "headers": list(df.columns),
            "preview": df.head(5).to_dict(orient="records")
        }
        return analysis

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


def list_uploaded_files(google_id: str):
    """Return a list of uploaded files for the given google_id."""
    files = list(db["uploaded_files"].find({"google_id": google_id}, {"_id": 0}))
    return files

#docker-compose.yml
version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    environment:
      - MONGO_URI=${MONGO_URI}
      - MINIO_ACCESS_KEY=${MINIO_ACCESS_KEY}
      - MINIO_SECRET_KEY=${MINIO_SECRET_KEY}
      - SESSION_SECRET_KEY=${SESSION_SECRET_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - FRONTEND_URL=${FRONTEND_URL}
      - MONGO_DB_NAME=${MONGO_DB_NAME}
      - MONGO_COLLECTION_NAME=${MONGO_COLLECTION_NAME}
    depends_on:
      - mongodb
      - minio
    networks:
      - app-network

  minio:
    image: minio/minio:latest
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ACCESS_KEY}
      - MINIO_ROOT_PASSWORD=${MINIO_SECRET_KEY}
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    networks:
      - app-network

volumes:
  minio-data:

networks:
  app-network:
    driver: bridge
#Dockerfile

# Use official Python 3.12 slim image as base
FROM python:3.12-slim

# Set the working directory inside the container
WORKDIR /app

# Copy requirements.txt first (to leverage Docker cache)
COPY requirements.txt .

# Install Python dependencies
RUN pip install --no-cache-dir -r requirements.txt

# Copy the application code into the container
COPY ./app ./app

# Expose port 8000 to match FastAPI default
EXPOSE 8000

# Run the FastAPI app using uvicorn
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]


